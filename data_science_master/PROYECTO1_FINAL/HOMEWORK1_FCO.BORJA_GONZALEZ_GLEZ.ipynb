{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 1. Finding the hidden writer. Fco. de Borja González.\n",
    "This first project is about figuring out who is the writer of a model using as input and training data .txt files that contain books of the two presumed writers using Naive Bayes Classifiers. This two famous writers are Verne and Maupassant and we will learn their differences in style through the probabilities of the different words they wrote on the texts we have been given. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, mutual_info_classif\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import naive_bayes, metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "import textwrap\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  File Reading and File Preprocessing.\n",
    "We have downloaded 4 books of each writer and and the novel we want to assing. The books will be stored on the input foldier. Since we have not much books to train, I will cut the books on 10 equal parts as if they were mini-books and I will retrieve the name of the writer (labels) from the title of the .txt document. This will be helpfull for perfomance purposes and for having more precise results on the % of classifications but the true results will depend on word's frecuency. Also, I have observed that all the books at the end have a generic part of generic data that is not important and it just slows our computer since they are characters and are stored on memory so I found in which character number do they begin and I delete from that point untill the end of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_path = os.getcwd()\n",
    "directory_books = os.path.join(initial_path, 'books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_classified = []\n",
    "authors_labels = []\n",
    "texts_unknown = []\n",
    "labels_unknown = []\n",
    "\n",
    "for idx, filename in enumerate(os.listdir(directory_books)):\n",
    "    data = open(os.path.join(directory_books, filename), encoding=\"latin-1\").read()\n",
    "    data = data.replace('\\n',' ')\n",
    "    data = data.replace('\\t',' ')\n",
    "    data = data[:data.find('END OF THIS PROJECT')]\n",
    "    for i in textwrap.wrap(data, math.ceil(len(data)/10)):\n",
    "        if len(i) > 40:\n",
    "                new_label = filename.split('-')\n",
    "                if new_label[0] != 'texte':\n",
    "                    authors_labels.append(new_label[0])\n",
    "                    texts_classified.append(i)\n",
    "                else:\n",
    "                    labels_unknown.append(new_label[0])\n",
    "                    texts_unknown.append(i)\n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have 2 lists with the same lenght, one with the different labels of the writer extracted from the titles of the .txt files and another with the chunks of text from the books with the garbage text of the end removed. Also we have the data to be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Labels of Chunks -->  80 ['maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'maupassant', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne', 'verne']\n",
      " \n",
      "Number of Unlabelled Chunks -->  10 ['texte', 'texte', 'texte', 'texte', 'texte', 'texte', 'texte', 'texte', 'texte', 'texte']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Labels of Chunks --> \", len(authors_labels), authors_labels)\n",
    "print(\" \")\n",
    "print(\"Number of Unlabelled Chunks --> \", len(labels_unknown), labels_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Labeled Chunks -->  80\n",
      " \n",
      "Number of Unabeled Chunks -->  10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Labeled Chunks --> \", len(texts_classified))\n",
    "print(\" \")\n",
    "print(\"Number of Unabeled Chunks --> \", len(texts_unknown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some numbers. \n",
    "We will check how many characters we have by writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>texts</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>BOULE DE SUIF   L'ÃPAVE--DÃCOUVERTE--UN PA...</td>\n",
       "      <td>22526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>annonÃ§a que dÃ©cidÃ©ment il se sentait un rud...</td>\n",
       "      <td>22524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>qu'est-ce que Ã§a vous fait?  Elle avait l'air...</td>\n",
       "      <td>22528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>potage, M. Follenvie reparut, rÃ©pÃ©tant sa ph...</td>\n",
       "      <td>22526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>Â«Il me raconta le sinistre, trÃ¨s simple d'ai...</td>\n",
       "      <td>22530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>dents jaunes et dÃ©mesurÃ©es.  On sentait, en ...</td>\n",
       "      <td>22523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>opÃ©ration, lui aurait paru prÃ©fÃ©rable. Elle...</td>\n",
       "      <td>22530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>glissait sur les lÃ¨vres. Depuis trente ans il...</td>\n",
       "      <td>22521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>autrefois. Nous ne nous quittions jamais; et l...</td>\n",
       "      <td>22529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>me piquaient Ã  prÃ©sent comme des coups d'aig...</td>\n",
       "      <td>22531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>CONTES DE LA BÃCASSE   SEIZIÃME ÃDITION  ...</td>\n",
       "      <td>21023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>qu'elle fut seule avec moi, je la saisis de no...</td>\n",
       "      <td>21028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>portant ainsi au bout du bras le chien suspend...</td>\n",
       "      <td>21027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>d'assister au spectacle de cette terreur super...</td>\n",
       "      <td>21028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>des assiettes.  En apportant le cafÃ©, elle ne...</td>\n",
       "      <td>21027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>en deux coups, sauver le bras de Javel cadet. ...</td>\n",
       "      <td>21028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>femmes et les filles de ses fermiers; ce qui n...</td>\n",
       "      <td>21028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>baron se ruinait pour elle. C'Ã©taient sans ce...</td>\n",
       "      <td>21028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>comprenez.Â»  Je ne dis rien.  Et je couchai d...</td>\n",
       "      <td>21024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>pas. Le paysan devenait fou. Il se leva pour a...</td>\n",
       "      <td>21025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>Le Horla    1887     LE HORLA     _8 mai._--...</td>\n",
       "      <td>25133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>encore, puis murmura:  --Je ne sais pas.  Je d...</td>\n",
       "      <td>25136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>et revenant Ã  pas tranquilles vers la porte, ...</td>\n",
       "      <td>25138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>homme. T'as du sang de poulet dans les veines....</td>\n",
       "      <td>25134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>nuage de fumÃ©e.  ... Nous Ã©tions Ã  table qu...</td>\n",
       "      <td>25131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>demain... Ã  la mÃªme heure... et j'ai... j'ai...</td>\n",
       "      <td>25138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>tendis ma carte.  Il la reÃ§ut et lut Ã  mi-vo...</td>\n",
       "      <td>25134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>celui avec qui on passe les longues soirÃ©es t...</td>\n",
       "      <td>25137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>il posa la main sur la croupe et ralentit le p...</td>\n",
       "      <td>25138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>maupassant</td>\n",
       "      <td>c'Ã©tait Ulrich, bien que ses cheveux fussent ...</td>\n",
       "      <td>25133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>verne</td>\n",
       "      <td>L'ÃLE MYSTÃRIEUSE  (1875)      Table des m...</td>\n",
       "      <td>124584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>verne</td>\n",
       "      <td>assez irrÃ©guliÃ¨re de monticules. ÃÃ  et lÃ ...</td>\n",
       "      <td>124585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>verne</td>\n",
       "      <td>d'attache Ã©tait fixÃ© au moyen d'une forte Ã©...</td>\n",
       "      <td>124585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>verne</td>\n",
       "      <td>House que leur graisse et leur peau, cette pea...</td>\n",
       "      <td>124583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>verne</td>\n",
       "      <td>mÃªme Ã  leur maximum d'Ã©lÃ©vation, ne devaie...</td>\n",
       "      <td>124585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>verne</td>\n",
       "      <td>tabac!  -- Ah! Ce brave Pencroff! Va-t-il Ãªtr...</td>\n",
       "      <td>124586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>verne</td>\n",
       "      <td>L'inconnu regarda l'ingÃ©nieur et sembla Ãªtre...</td>\n",
       "      <td>124586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>verne</td>\n",
       "      <td>Le vent Ã©tait tombÃ© complÃ¨tement avec le cr...</td>\n",
       "      <td>124586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>verne</td>\n",
       "      <td>Une fois Ã  ce point, en remontant la rive dro...</td>\n",
       "      <td>124583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>verne</td>\n",
       "      <td>cime de la montagne, et l'on put mÃªme reconna...</td>\n",
       "      <td>124586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>verne</td>\n",
       "      <td>LE TOUR DU MONDE EN QUATRE-VINGTS JOURS  (18...</td>\n",
       "      <td>43292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>verne</td>\n",
       "      <td>facultÃ©s mentales de son auteur.  Des article...</td>\n",
       "      <td>43295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>verne</td>\n",
       "      <td>observation faite, Mr. Fogg continua tranquill...</td>\n",
       "      <td>43299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>verne</td>\n",
       "      <td>Ã  la lueur des torches, et une vague lumiÃ¨re...</td>\n",
       "      <td>43297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>verne</td>\n",
       "      <td>marques de la plus extrÃªme surprise. Passepar...</td>\n",
       "      <td>43299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>verne</td>\n",
       "      <td>Que l'on juge donc du coup d'assommoir qu'il r...</td>\n",
       "      <td>43298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>verne</td>\n",
       "      <td>vaste case, que couronnaient plusieurs faiscea...</td>\n",
       "      <td>43300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>verne</td>\n",
       "      <td>Phileas Fogg, la jeune femme, Fix et Passepart...</td>\n",
       "      <td>43300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>verne</td>\n",
       "      <td>accompagnÃ¨rent, mais elles ne venaient point ...</td>\n",
       "      <td>43299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>verne</td>\n",
       "      <td>livres pouvait bien finir par voler un bÃ¢time...</td>\n",
       "      <td>43296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>verne</td>\n",
       "      <td>VOYAGE  AU  CENTRE DE  LA TERRE     I   Le 2...</td>\n",
       "      <td>42951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>verne</td>\n",
       "      <td>Cependant jamais demande ne fut formulÃ©e d'un...</td>\n",
       "      <td>42949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>verne</td>\n",
       "      <td>sur la cÃ´te mÃ©ridionale de l'Islande.  La tr...</td>\n",
       "      <td>42948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>verne</td>\n",
       "      <td>guirlande d'anges insuffisamment dÃ©barbouillÃ...</td>\n",
       "      <td>42950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>verne</td>\n",
       "      <td>sur son dos le paquet des instruments; Hans pr...</td>\n",
       "      <td>42943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>verne</td>\n",
       "      <td>surprendre les murmures de quelque source.  Ma...</td>\n",
       "      <td>42949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>verne</td>\n",
       "      <td>rÃ©flÃ©chi.  Un certain espoir, vague encore, ...</td>\n",
       "      <td>42949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>verne</td>\n",
       "      <td>m'appuie au tronc des conifÃ¨res immenses; je ...</td>\n",
       "      <td>42951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>verne</td>\n",
       "      <td>professeur Lidenbrock, la stupÃ©faction, l'inc...</td>\n",
       "      <td>42942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>verne</td>\n",
       "      <td>tremblement de terre dans ce sol coupÃ© de fis...</td>\n",
       "      <td>42947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        author                                              texts  Length\n",
       "0   maupassant    BOULE DE SUIF   L'ÃPAVE--DÃCOUVERTE--UN PA...   22526\n",
       "1   maupassant  annonÃ§a que dÃ©cidÃ©ment il se sentait un rud...   22524\n",
       "2   maupassant  qu'est-ce que Ã§a vous fait?  Elle avait l'air...   22528\n",
       "3   maupassant  potage, M. Follenvie reparut, rÃ©pÃ©tant sa ph...   22526\n",
       "4   maupassant  Â«Il me raconta le sinistre, trÃ¨s simple d'ai...   22530\n",
       "5   maupassant  dents jaunes et dÃ©mesurÃ©es.  On sentait, en ...   22523\n",
       "6   maupassant  opÃ©ration, lui aurait paru prÃ©fÃ©rable. Elle...   22530\n",
       "7   maupassant  glissait sur les lÃ¨vres. Depuis trente ans il...   22521\n",
       "8   maupassant  autrefois. Nous ne nous quittions jamais; et l...   22529\n",
       "9   maupassant  me piquaient Ã  prÃ©sent comme des coups d'aig...   22531\n",
       "10  maupassant    CONTES DE LA BÃCASSE   SEIZIÃME ÃDITION  ...   21023\n",
       "11  maupassant  qu'elle fut seule avec moi, je la saisis de no...   21028\n",
       "12  maupassant  portant ainsi au bout du bras le chien suspend...   21027\n",
       "13  maupassant  d'assister au spectacle de cette terreur super...   21028\n",
       "14  maupassant  des assiettes.  En apportant le cafÃ©, elle ne...   21027\n",
       "15  maupassant  en deux coups, sauver le bras de Javel cadet. ...   21028\n",
       "16  maupassant  femmes et les filles de ses fermiers; ce qui n...   21028\n",
       "17  maupassant  baron se ruinait pour elle. C'Ã©taient sans ce...   21028\n",
       "18  maupassant  comprenez.Â»  Je ne dis rien.  Et je couchai d...   21024\n",
       "19  maupassant  pas. Le paysan devenait fou. Il se leva pour a...   21025\n",
       "20  maupassant    Le Horla    1887     LE HORLA     _8 mai._--...   25133\n",
       "21  maupassant  encore, puis murmura:  --Je ne sais pas.  Je d...   25136\n",
       "22  maupassant  et revenant Ã  pas tranquilles vers la porte, ...   25138\n",
       "23  maupassant  homme. T'as du sang de poulet dans les veines....   25134\n",
       "24  maupassant  nuage de fumÃ©e.  ... Nous Ã©tions Ã  table qu...   25131\n",
       "25  maupassant  demain... Ã  la mÃªme heure... et j'ai... j'ai...   25138\n",
       "26  maupassant  tendis ma carte.  Il la reÃ§ut et lut Ã  mi-vo...   25134\n",
       "27  maupassant  celui avec qui on passe les longues soirÃ©es t...   25137\n",
       "28  maupassant  il posa la main sur la croupe et ralentit le p...   25138\n",
       "29  maupassant  c'Ã©tait Ulrich, bien que ses cheveux fussent ...   25133\n",
       "..         ...                                                ...     ...\n",
       "50       verne    L'ÃLE MYSTÃRIEUSE  (1875)      Table des m...  124584\n",
       "51       verne  assez irrÃ©guliÃ¨re de monticules. ÃÃ  et lÃ ...  124585\n",
       "52       verne  d'attache Ã©tait fixÃ© au moyen d'une forte Ã©...  124585\n",
       "53       verne  House que leur graisse et leur peau, cette pea...  124583\n",
       "54       verne  mÃªme Ã  leur maximum d'Ã©lÃ©vation, ne devaie...  124585\n",
       "55       verne  tabac!  -- Ah! Ce brave Pencroff! Va-t-il Ãªtr...  124586\n",
       "56       verne  L'inconnu regarda l'ingÃ©nieur et sembla Ãªtre...  124586\n",
       "57       verne  Le vent Ã©tait tombÃ© complÃ¨tement avec le cr...  124586\n",
       "58       verne  Une fois Ã  ce point, en remontant la rive dro...  124583\n",
       "59       verne  cime de la montagne, et l'on put mÃªme reconna...  124586\n",
       "60       verne    LE TOUR DU MONDE EN QUATRE-VINGTS JOURS  (18...   43292\n",
       "61       verne  facultÃ©s mentales de son auteur.  Des article...   43295\n",
       "62       verne  observation faite, Mr. Fogg continua tranquill...   43299\n",
       "63       verne  Ã  la lueur des torches, et une vague lumiÃ¨re...   43297\n",
       "64       verne  marques de la plus extrÃªme surprise. Passepar...   43299\n",
       "65       verne  Que l'on juge donc du coup d'assommoir qu'il r...   43298\n",
       "66       verne  vaste case, que couronnaient plusieurs faiscea...   43300\n",
       "67       verne  Phileas Fogg, la jeune femme, Fix et Passepart...   43300\n",
       "68       verne  accompagnÃ¨rent, mais elles ne venaient point ...   43299\n",
       "69       verne  livres pouvait bien finir par voler un bÃ¢time...   43296\n",
       "70       verne    VOYAGE  AU  CENTRE DE  LA TERRE     I   Le 2...   42951\n",
       "71       verne  Cependant jamais demande ne fut formulÃ©e d'un...   42949\n",
       "72       verne  sur la cÃ´te mÃ©ridionale de l'Islande.  La tr...   42948\n",
       "73       verne  guirlande d'anges insuffisamment dÃ©barbouillÃ...   42950\n",
       "74       verne  sur son dos le paquet des instruments; Hans pr...   42943\n",
       "75       verne  surprendre les murmures de quelque source.  Ma...   42949\n",
       "76       verne  rÃ©flÃ©chi.  Un certain espoir, vague encore, ...   42949\n",
       "77       verne  m'appuie au tronc des conifÃ¨res immenses; je ...   42951\n",
       "78       verne  professeur Lidenbrock, la stupÃ©faction, l'inc...   42942\n",
       "79       verne  tremblement de terre dans ce sol coupÃ© de fis...   42947\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "info = pd.DataFrame({'author': authors_labels, 'texts': texts_classified})\n",
    "info['Length']  = info['texts'].str.len()\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of characters written by chunk\n",
      " \n",
      "               Length\n",
      "author               \n",
      "maupassant  28427.825\n",
      "verne       62050.875\n",
      " \n",
      "Number or characters by author --> \n",
      " \n",
      "             Length\n",
      "author             \n",
      "maupassant  1137113\n",
      "verne       2482035\n"
     ]
    }
   ],
   "source": [
    "print(\"Average of characters written by chunk\")\n",
    "print(\" \")\n",
    "print(info.groupby('author').mean())\n",
    "print(\" \")\n",
    "print(\"Number or characters by author --> \")\n",
    "print(\" \")\n",
    "print( info.groupby('author').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the average lenght of each chunk depends on the author. This might be a problem that would cause overfitting and balancing problems but it is the data we have. It also makes sense that the lenght of the chunks written by Verne have more or less two times more words since it is consequent with the number of characters we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing.\n",
    "Once we have all the files processed the data is ready to be studied and preprocessed for a good Machine Learning and Statistical Modelling part which is what I will be doing on this next section. We will begin by turning the names of the authors to a boolean variable 0 - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors encoded -->  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1]\n",
      "Number of chunks by author\n",
      "{0: 40, 1: 40}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['maupassant', 'verne'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(authors_labels)\n",
    "authors_encoded = label_encoder.transform(authors_labels)\n",
    "print(\"Authors encoded --> \", authors_encoded)\n",
    "print(\"Number of chunks by author\")\n",
    "unique, counts = np.unique(authors_encoded, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Set Splitting\n",
    "\n",
    "I will continue by splitting the dataset. The most common distribution of the sets is a 70 - 30 splitting. Latter on we could try to change this proportion if necessary. For the random_state parameter If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_train, chunks_test, authors_train, authors_test = train_test_split(\n",
    "    texts_classified, authors_encoded, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, list, 'pas. Le paysan devenait fou. Il se leva ')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_train), type(chunks_train), chunks_train[0][0:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Integer Data.\n",
    "As we know, the ML algorithms are used to work using integer data. We have some nice tools for this step.\n",
    "We will begin by defining the parameters of our tfidf vectorizer model. use_idf : boolean, default=True\n",
    "Enable inverse-document-frequency reweighting.\n",
    "\n",
    "smooth_idf : boolean, default=True\n",
    "Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.\n",
    "\n",
    "sublinear_tf : boolean, default=False\n",
    "Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "\n",
    "\n",
    "Definition of the tfidf vectorizer. Arguments provided here are may be key for the final outcome.\n",
    "In particular we have modified the token pattern so that symbols are kept on the matrix (they may be relevant for the writing style of the author)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "args = {\n",
    "    \"encoding\": \"latin-1\", \n",
    "    \"stop_words\": None, # They may reflect the style of the author\n",
    "    \"token_pattern\": r\"(?u)\\b\\w\\w+\\b|\\r|\\n|\\'|\\\"|\\¿|\\?|¡|!|\\(|\\)|\\[|\\]|<|>|,|;|:|\\-+|\\.\", # Keep punctuation symbols\n",
    "    \"lowercase\": True, \n",
    "    \"norm\": \"l2\", \n",
    "    \"use_idf\": True, \n",
    "    \"smooth_idf\": True,\n",
    "    \"sublinear_tf\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vectorization (take words from train set, then convert test and anonymous data)\n",
    "vectorizer = TfidfVectorizer(**args)\n",
    "features_train = vectorizer.fit_transform(chunks_train)\n",
    "features_test = vectorizer.transform(chunks_test)\n",
    "features_unknown = vectorizer.transform(texts_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<56x21693 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 105709 stored elements in Compressed Sparse Row format>,\n",
       " <24x21693 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 45384 stored elements in Compressed Sparse Row format>,\n",
       " <10x21693 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 35675 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train, features_test, features_unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES TRAIN SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random element of matrix Random element of matrix 0.05333923925193049\n",
      "Random element of matrix 0.0\n",
      "[[0.03830714 0.05333924 0.         ... 0.02215198 0.         0.        ]\n",
      " [0.03044604 0.04013846 0.02318944 ... 0.01618951 0.         0.        ]\n",
      " [0.03511526 0.04265717 0.         ... 0.02056718 0.         0.        ]\n",
      " ...\n",
      " [0.02881812 0.04082189 0.         ... 0.02090617 0.         0.        ]\n",
      " [0.03258146 0.05496299 0.01446825 ... 0.02252954 0.         0.        ]\n",
      " [0.02433734 0.04168538 0.00979558 ... 0.0198623  0.02026281 0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56, 21693)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Random element of matrix\", \"Random element of matrix\", features_train[0,1])\n",
    "print(\"Random element of matrix\", features_train[0,21691])\n",
    "print(features_train.todense())\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES TEST SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random element of matrix 0.043543614595100255\n",
      "Random element of matrix 0.012697247225141354\n",
      "[[0.03265898 0.04354361 0.0248004  ... 0.01982884 0.01269725 0.        ]\n",
      " [0.04448387 0.05683504 0.         ... 0.02047475 0.0175663  0.        ]\n",
      " [0.02563331 0.04421765 0.         ... 0.02422752 0.02158729 0.        ]\n",
      " ...\n",
      " [0.03321127 0.05780643 0.01474792 ... 0.01846939 0.         0.        ]\n",
      " [0.03010997 0.0423878  0.01017807 ... 0.02210261 0.         0.        ]\n",
      " [0.02657677 0.03326914 0.01150884 ... 0.02052649 0.00830447 0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 21693)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Random element of matrix\", features_test[0,1])\n",
    "print(\"Random element of matrix\", features_test[0,21691])\n",
    "print(features_test.todense())\n",
    "features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, we have created matrices with words as columns with their weights as values. The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus.\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "Since we will be playing just with the words used on the training set and despite the fact that the set of words is rather big the classes need to be balanced in order not to omit words on the test that might not be on the train set. Let see how balanced are the clases of the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks by author\n",
      "{0: 29, 1: 27}\n"
     ]
    }
   ],
   "source": [
    "authors_train\n",
    "print(\"Number of chunks by author\")\n",
    "unique, counts = np.unique(authors_train, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventhough the classes may look well balanced we have previously seen that the number of characters we have for Jules Verne is two times the number we have for Maupassant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE SELECTION.\n",
    "In order to make some dimensionality reduction, improve the performance of the model and reduce the variance we are going to perform a little feature selection since our matrix is too big as we have seen. With sklearn.feature_selection.SelectPercentile we select features according to a percentile of the highest scores. With the threshold parameter we can control what happens when we select the most influent ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of the features BEFORE selection -->  (56, 21693)\n",
      " \n",
      "[[0.03830714 0.05333924 0.         ... 0.02215198 0.         0.        ]\n",
      " [0.03044604 0.04013846 0.02318944 ... 0.01618951 0.         0.        ]\n",
      " [0.03511526 0.04265717 0.         ... 0.02056718 0.         0.        ]\n",
      " ...\n",
      " [0.02881812 0.04082189 0.         ... 0.02090617 0.         0.        ]\n",
      " [0.03258146 0.05496299 0.01446825 ... 0.02252954 0.         0.        ]\n",
      " [0.02433734 0.04168538 0.00979558 ... 0.0198623  0.02026281 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "selector = SelectPercentile(f_classif, percentile = threshold)\n",
    "selector.fit(features_train, authors_train)\n",
    "print(\"Lenght of the features BEFORE selection --> \", features_train.shape)\n",
    "print(\" \")\n",
    "print(features_train.todense())\n",
    "features_train = selector.transform(features_train).toarray()\n",
    "features_test = selector.transform(features_test).toarray()\n",
    "features_unknown = selector.transform(features_unknown).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of the features AFTER selection -->  (56, 651)\n",
      " \n",
      "[[0.05333924 0.0575891  0.03581479 ... 0.01597212 0.025451   0.        ]\n",
      " [0.04013846 0.04378896 0.03365771 ... 0.01352353 0.00590167 0.        ]\n",
      " [0.04265717 0.04312512 0.03498056 ... 0.01138837 0.01969507 0.        ]\n",
      " ...\n",
      " [0.04082189 0.04355165 0.03069472 ... 0.01700475 0.01666168 0.        ]\n",
      " [0.05496299 0.05938145 0.03676384 ... 0.00959417 0.0229283  0.        ]\n",
      " [0.04168538 0.04418123 0.03051048 ... 0.01913556 0.01660799 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lenght of the features AFTER selection --> \", features_train.shape)\n",
    "print(\" \")\n",
    "print(features_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have reduced quite a lot the dimension of our matrix. This method seems to take into account the intracolumn variance and if it is a word that appears quite the same number of times by document it is discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen Words.\n",
    "Does it exist a way to check which words we have chosen and which ones we have selected as most influent? The answer is YES.\n",
    "And we can retrieve them in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get idxs of columns kept\n",
    "index_word = selector.get_support(indices=True)\n",
    "#print(\"Index of words chosen\", index_word)\n",
    "words = vectorizer.get_feature_names()\n",
    "#print(\"All words used\", words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words taken after selection ( 3 % most relevant only): 651\n",
      "\n",
      "Features:\n",
      " [\"'\", ',', '-', '--', '.', '11', '21', ':', ';', '[', ']', 'abondamment', 'absolu', 'absolument', 'accord', 'accosta', 'accã', 'action', 'actuellement', 'administration', 'agi', 'agir', 'agissait', 'agit', 'agrã', 'ailleurs', 'aimã', 'ainsi', 'aisã', 'alla', 'alors', 'amour', 'amã', 'angle', 'angoisse', 'animaux', 'ans', 'appareil', 'appartenait', 'arc', 'argent', 'aride', 'arriver', 'arrivã', 'aspect', 'assez', 'assit', 'atmosphã', 'atteindre', 'attraction', 'au', 'aucune', 'aucunement', 'audacieux', 'auquel', 'auraient', 'aurions', 'aurons', 'autre', 'aux', 'avait', 'avec', 'avons', 'avouer', 'axel', 'ayons', 'baie', 'ballon', 'bas', 'base', 'bien', 'blancs', 'bleu', 'bonne', 'bouche', 'bout', 'bras', 'brusquement', 'but', 'bã', 'bãªte', 'cabine', 'calculã', 'canot', 'cap', 'capitale', 'cas', 'ce', 'ceci', 'celle', 'celles', 'cent', 'centaine', 'central', 'centrale', 'centre', 'cents', 'cependant', 'certain', 'certaine', 'certains', 'cessaire', 'cessairement', 'cesse', 'cessitã', 'chaise', 'chambre', 'chances', 'chapitre', 'chapper', 'chappã', 'cheveux', 'chez', 'choc', 'chronomã', 'chute', 'chã', 'ci', 'cieux', 'cinquante', 'cisã', 'clara', 'clat', 'cles', 'coeur', 'comme', 'commencer', 'communication', 'compagnons', 'composã', 'comprise', 'compte', 'comptã', 'condition', 'conditions', 'constater', 'construction', 'consã', 'continent', 'contraire', 'convenablement', 'convenir', 'conversation', 'corce', 'couches', 'coup', 'craindre', 'creusã', 'cria', 'croire', 'curieux', 'curã', 'dans', 'de', 'debout', 'dedans', 'degrã', 'delã', 'demi', 'derriã', 'des', 'destinã', 'deux', 'devaient', 'devait', 'devant', 'dieu', 'difficile', 'digne', 'directement', 'direction', 'diriger', 'dirigã', 'disposition', 'disposã', 'disque', 'distance', 'dition', 'divers', 'diverses', 'doux', 'du', 'duquel', 'durent', 'dã', 'eaux', 'effarã', 'effet', 'eh', 'elle', 'ellement', 'embarcation', 'embarquã', 'employer', 'emprisonnã', 'en', 'endroit', 'enfants', 'engins', 'entendre', 'entiã', 'entra', 'entraã', 'entrer', 'environ', 'es', 'espoir', 'espã', 'estimer', 'et', 'europe', 'eussent', 'exacte', 'exactement', 'exaspã', 'existait', 'explication', 'exploration', 'explosion', 'expã', 'extrã', 'extrãªme', 'extrãªmement', 'eã', 'face', 'facile', 'faction', 'faire', 'faisait', 'faite', 'fallait', 'favorable', 'femme', 'femmes', 'fenãªtre', 'fidã', 'fier', 'fille', 'filles', 'fils', 'flexion', 'folle', 'formait', 'forme', 'forment', 'formã', 'franchi', 'franchir', 'francs', 'frã', 'furent', 'furieux', 'fusion', 'gai', 'gale', 'gaz', 'gions', 'globe', 'gorge', 'grand', 'grandeur', 'gros', 'grotte', 'grã', 'habitã', 'hauteur', 'heureusement', 'histoires', 'homme', 'hommes', 'horrible', 'hors', 'humanitã', 'hypothã', 'il', 'ils', 'imagination', 'importante', 'importe', 'impossible', 'inattendu', 'incessamment', 'incident', 'incidents', 'indispensable', 'influence', 'infã', 'ingã', 'instant', 'instants', 'instrument', 'instruments', 'insuffisante', 'intensitã', 'intã', 'inutile', 'ix', 'je', 'jeunes', 'joues', 'jour', 'la', 'lac', 'laissait', 'lancã', 'laquelle', 'largement', 'largeur', 'latitude', 'le', 'lectricitã', 'lectrique', 'lectriques', 'lentement', 'lequel', 'les', 'lesquels', 'leva', 'lidenbrock', 'ligne', 'limites', 'lisiã', 'lit', 'livres', 'loignã', 'longtemps', 'lorsque', 'lui', 'lutter', 'lã', 'ma', 'madame', 'mains', 'maintenir', 'mais', 'maison', 'manquaient', 'manquait', 'manquer', 'manquã', 'mari', 'marin', 'mariã', 'mars', 'masse', 'masses', 'matiã', 'me', 'mener', 'mer', 'mers', 'merveilleuse', 'mesurait', 'mille', 'milles', 'milliers', 'minã', 'mirent', 'mit', 'mitã', 'mme', 'modifiã', 'moins', 'moment', 'montagnes', 'moyen', 'moyenne', 'murmura', 'murs', 'mã', 'mãªme', 'navigation', 'ne', 'nes', 'neuf', 'ni', 'nieur', 'niveau', 'nombre', 'nombreux', 'nord', 'norme', 'nouvelle', 'nt', 'nul', 'nulle', 'objet', 'objets', 'observait', 'observation', 'observations', 'observer', 'observã', 'occupa', 'ocã', 'odeur', 'oeil', 'offrait', 'oh', 'on', 'opã', 'orifice', 'ouest', 'outils', 'ouvrit', 'pacifique', 'pain', 'par', 'parallã', 'parents', 'paroi', 'parois', 'paroles', 'part', 'particuliã', 'partie', 'pas', 'passage', 'paysans', 'peau', 'perdre', 'permettait', 'personnage', 'petit', 'petite', 'petits', 'peur', 'pic', 'placement', 'pleurait', 'pleurer', 'plus', 'poids', 'points', 'poitrine', 'pondit', 'ponse', 'poque', 'porte', 'portion', 'portions', 'portã', 'poste', 'postã', 'pour', 'pourrait', 'pourrons', 'pouvaient', 'pouvait', 'pouvons', 'presqu', 'pression', 'prix', 'probable', 'procã', 'produire', 'produisait', 'produit', 'produite', 'professeur', 'profondeur', 'projet', 'prolonger', 'prononcã', 'proportion', 'puis', 'purent', 'put', 'pã', 'qu', 'quand', 'quant', 'quantitã', 'quartiers', 'que', 'quelques', 'quemment', 'quence', 'quent', 'question', 'qui', 'quitter', 'quittã', 'rablement', 'raison', 'ramener', 'ramenã', 'rapidement', 'rapiditã', 'rappela', 'rapprochã', 'ration', 'rature', 'raux', 'rayons', 're', 'regagner', 'regarder', 'regards', 'relativement', 'relevã', 'rement', 'remontã', 'rence', 'rendre', 'renfermait', 'renfermã', 'reporter', 'reprendre', 'rer', 'retard', 'retenir', 'retour', 'retrouver', 'ricain', 'ricains', 'ridionale', 'rien', 'rieur', 'rieure', 'rieures', 'rieusement', 'rique', 'riques', 'rire', 'ritable', 'ritablement', 'ritables', 'rivage', 'rivages', 'rive', 'roches', 'rocs', 'ros', 'rã', 'rãªt', 'sa', 'sans', 'satisfaction', 'saurait', 'savant', 'savants', 'science', 'se', 'seize', 'sence', 'sensiblement', 'sept', 'septentrionale', 'sera', 'serons', 'servã', 'ses', 'si', 'signal', 'silencieusement', 'sinon', 'situã', 'soin', 'soir', 'soit', 'soixante', 'solide', 'solidement', 'somme', 'son', 'sortit', 'soudain', 'soudre', 'sourit', 'sphã', 'substance', 'succã', 'sud', 'suffisait', 'suffisamment', 'sultat', 'suppose', 'supã', 'sur', 'surface', 'systã', 'table', 'tabli', 'tablir', 'tait', 'tale', 'tant', 'tat', 'tats', 'telle', 'tellement', 'tempã', 'tempãªtes', 'tenir', 'terminã', 'terrestre', 'terrestres', 'thã', 'tiers', 'toit', 'toujours', 'tous', 'tout', 'toutefois', 'trains', 'transporter', 'transportã', 'traversã', 'trente', 'trer', 'triste', 'trou', 'trouvaient', 'tã', 'un', 'une', 'union', 'unis', 'ustensiles', 'utile', 'vainement', 'valeur', 'vapeur', 'vapeurs', 'ventre', 'videmment', 'vident', 'vie', 'vieille', 'vieux', 'vif', 'vigoureusement', 'vii', 'viii', 'village', 'vingt', 'vingts', 'vite', 'vitesse', 'vives', 'voisin', 'voix', 'volatiles', 'volã', 'vous', 'voyage', 'vraisemblablement', 'vã', 'yeux', 'zã']\n"
     ]
    }
   ],
   "source": [
    "influent_words = [words[i] for i in index_word] \n",
    "print(\"Number of words taken after selection (\", threshold, \"% most relevant only):\", len(influent_words))\n",
    "print(\"\\nFeatures:\\n\", influent_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many models usually make use of a thing called stop_words. This is to delete the most common stop words from a language such as \"and\", \"up\" or \"under\" but I think that they might reflect the style of the author and also if they are not too informative they have been removed with selectPercentile feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling. \n",
    "Once we have done all the preprocessing part and studied a little bit the inputs of the model we can begin performing some modellization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifiers\n",
    "Naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naive) independence assumptions between the features **which is clearly our case** since written words do not have nothing to do among themselves. \n",
    "\n",
    "It has been studied extensively since the 1950s and remains a popular (baseline) method for text categorization, the problem of judging documents as belonging to one category or the other (such as spam or legitimate, sports or politics, etc.) with word frequencies as the features. With appropriate pre-processing, it is competitive in this domain with more advanced methods including support vector machines.It also finds application in automatic medical diagnosis.\n",
    "\n",
    "Naive Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features/predictors) in a learning problem  and requires a small number of training data to estimate the parameters necessary for classification.\n",
    "\n",
    "If we go to the sklearn documentation we can check that there are 4 different Naive Bayes algorithms:\n",
    "\n",
    " 1. Gaussian NB: The likelihood of the features is assumed to be Gaussian.\n",
    " 2. Multinomial NB: implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification.\n",
    " 3. Complement NB implements the complement naive Bayes (CNB) algorithm. CNB is an adaptation of the standard multinomial naive Bayes (MNB) algorithm that is particularly suited for imbalanced data sets.\n",
    " 4. BernoulliNB implements the naive Bayes training and classification algorithms for data that is distributed according to multivariate Bernoulli distributions; i.e., there may be multiple features but each one is assumed to be a binary-valued (Bernoulli, boolean) variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: for model GaussianNB(priors=None, var_smoothing=1e-09) 1.0\n",
      "Test set accuracy: 0.6666666666666666\n",
      " \n",
      "Train set accuracy: for model MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) 0.8571428571428571\n",
      "Test set accuracy: 0.8333333333333334\n",
      " \n",
      "Train set accuracy: for model MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True) 0.9285714285714286\n",
      "Test set accuracy: 0.8333333333333334\n",
      " \n",
      "Train set accuracy: for model MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True) 1.0\n",
      "Test set accuracy: 1.0\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#clf_list = [GaussianNB(), MultinomialNB() ,ComplementNB(), BernoulliNB()]\n",
    "#from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf_list = [GaussianNB(), MultinomialNB(), MultinomialNB(0.5), MultinomialNB(0.1)]#, BernoulliNB()]\n",
    "\n",
    "for NB in clf_list:\n",
    "    # Train and predict steps\n",
    "    #print(NB)\n",
    "    NB.fit(features_train, authors_train)\n",
    "    authors_train_predicted = NB.predict(features_train)\n",
    "    authors_test_predicted = NB.predict(features_test)\n",
    "    acc_train = accuracy_score(authors_train, authors_train_predicted)\n",
    "    print(\"Train set accuracy: for model {}\".format(NB), acc_train)\n",
    "    acc_test = accuracy_score(authors_test, authors_test_predicted)\n",
    "    print(\"Test set accuracy:\", acc_test)\n",
    "    print(\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and conclusions\n",
    "### Naive Bayes Classifiers\n",
    "As we can see the Gaussian model is the one with the lowest performance on test set after scoring with 100% on train. Thus, we have clear signs of overfitting. This model is only a good choice if the distribution of the variables is Gaussian.\n",
    "We can check the probability distribution of 7 random words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Distribution by document of word number 61 which is avec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Distribution by document of word number 268 which is homme\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Distribution by document of word number 173 which is disposition\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Distribution by document of word number 256 which is gions\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Distribution by document of word number 175 which is disque\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Distribution by document of word number 447 which is pouvaient\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Distribution by document of word number 332 which is mains\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indx_word = np.random.randint(1,len(influent_words),7)\n",
    "for i in indx_word:\n",
    "    print(\"Probability Distribution by document of word number\", i, \"which is\", influent_words[i])\n",
    "    plt.hist(features_train[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the probability distribution of our words is not gaussian so this might be the reason why GaussianNB might not be the best model. This is why the multinomial model performs the best with an $\\alpha$ parameter of 0.1 and the model improves as we decrease $\\alpha$. I know that there is a ***Bernoulli NB model*** but I have not used it since our features are not binary.\n",
    "There is one more NB classifier on sklearn which is ***Complement Naive Bayes*** but I can not use it because it is just implemented on the development mode of the last version on sklearn and that is hard to install with Anaconda distribution on Windows. This could be the best model since it is for unbalanced data that could be our case since we have seen that there is two times more words from Verne than from Maupassant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Prediction\n",
    "Now, let us accomplish the final step of our work. Try to guess who has written the misteryous book. For that, we are going to check between the models what are the answers.:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "% of Vernes 100.0\n",
      "['verne' 'verne' 'verne' 'verne' 'verne' 'verne' 'verne' 'verne' 'verne'\n",
      " 'verne']\n",
      " \n",
      "Predictions for MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "[0 1 1 1 1 0 1 1 1 0]\n",
      "% of Vernes 70.0\n",
      "['maupassant' 'verne' 'verne' 'verne' 'verne' 'maupassant' 'verne' 'verne'\n",
      " 'verne' 'maupassant']\n",
      " \n",
      "Predictions for MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True)\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "% of Vernes 100.0\n",
      "['verne' 'verne' 'verne' 'verne' 'verne' 'verne' 'verne' 'verne' 'verne'\n",
      " 'verne']\n",
      " \n",
      "Predictions for MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "% of Vernes 100.0\n",
      "['verne' 'verne' 'verne' 'verne' 'verne' 'verne' 'verne' 'verne' 'verne'\n",
      " 'verne']\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Predict the docs with unknown author\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf_list = [GaussianNB(), MultinomialNB(), MultinomialNB(0.5), MultinomialNB(0.1)]#, BernoulliNB()]\n",
    "\n",
    "for NB in clf_list:\n",
    "    NB.fit(features_train, authors_train)\n",
    "    authors_unknown_predicted = NB.predict(features_unknown)\n",
    "    print (\"Predictions for {}\".format(NB))\n",
    "    print(authors_unknown_predicted)\n",
    "    vernes = np.sum((authors_unknown_predicted))/len(authors_unknown_predicted) *100\n",
    "    print(\"% of Vernes {}\".format(vernes))\n",
    "    print(label_encoder.inverse_transform(authors_unknown_predicted))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final conclusions\n",
    "As we have seen most of the models do not show any kind of doubt about the writer of the chunk. 3 Of 4 models say that all the chunks have been written by Verne and in just one we get a little bit more doubts. But we know that it was not the best model so that result does not need to be taken into account. \n",
    "\n",
    "We can know that Verne is the writer just by opening the .txt and reading the title of the book which is ***LES ENFANTS DU CAPITAINE GRANT*** , a novel by the French writer Jules Verne, published in 1867–1868. So, we can be quite happy about the performance of our algorithm which is also very fast to train and compile, another good feature of Naive Bayes classifiers.\n",
    "\n",
    "To end up I am very happy with the outcomes of this work since I had never done nothing related to NLP and text mining and I have found it a very interesting task and I have also learnt a lot of things about text analysis and statistics. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
