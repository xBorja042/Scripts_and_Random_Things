{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC Decipher.\n",
    "\n",
    "We want to use a MCMC scheme to decipher a text. In statistics, Markov chain Monte Carlo (MCMC) methods comprise a class of algorithms for sampling from a probability distribution. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by observing the chain after a number of steps. The more steps there are, the more closely the distribution of the sample matches the actual desired distribution. A Markov Chain is a mathematical model of stochastican systems whose state only depends on the state of the right previous moment. \n",
    "\n",
    "As described on the course notes A simple cipher method is to attribute a number to each character: a text is then coded by a list of numbers. Then we choose a permutation that belongs to the number of characters. A text is seen as a Markov Chain (in the space of the characters) with transition matrix M. To each candidate for deciphering we attribute a score and the higher the most likely it is to be the true deciphering.\n",
    "\n",
    "In our case the Markov Chain would be the deciphered text. We need to compute all the probabilities of having character x' at t1, given that the character at t0 was x. So, we need to study these probabilities such as Prob(char(t1)=x' | char(t0) = x) for x' and x belonging to the character space X.  These probabilities are going to be studied by loading several books in English and counting all the cases.\n",
    "\n",
    "## Initial Imports and path declaring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "path = \"C:\\\\Users\\\\Borja042\\\\Desktop\\\\MASTER2\\\\PERIODO_2\\\\STATS2\\\\PROYECTO2\"\n",
    "path_books1 = path + \"\\\\Books\\\\\"\n",
    "path_books = path + \"\\\\booksF\\\\\"\n",
    "path_ciphered = path + \"\\\\cipher\\\\ciphered-tex.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define all the possible values of our character space X and the dimension of such space. We will also build a key-value structure (python dictionary) for finding after the position of each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_spc =  [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\",\" \",\".\",\",\",\";\",\":\",\"?\",\"!\",\"-\",\"'\",\"\\\"\"]\n",
    "dim = len(chars_spc)\n",
    "chars_ids = {}\n",
    "for i in range(dim):\n",
    "    chars_ids[chars_spc[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition matrix M. \n",
    "\n",
    "**Stochastic matrix** is a square matrix used to describe the transitions of a Markov chain. Each of its entries is a nonnegative real number representing a probability.\n",
    "If the probability of moving from i  to  j in one time step is  $Pr(j|i)=P_{i,j}$, the stochastic matrix  P is given by using  $P_{i,j}$ as the  $i^{th}$ row and  $j^{th}$ column element. For example:\n",
    "\n",
    "$M = \\begin{bmatrix}P_{11} & P_{12}\\\\P_{21} & P_{22}\\end{bmatrix}$\n",
    "\n",
    "To achieve this, we will read books from the suggested webpage, Gutenberg and we will count the amounts of time we went from one character to another and with that, the probability of going from 1 to another. The books we have chosen are huckleberry_finn.txt, peter_pan.txt, romeo_juliet.txt,  sherlock_holmes.txt,  wizard_oz.txt and sleepy hollow. I tried to be all of them written originially on english, not a translation.\n",
    "\n",
    "The more books we include and the more writing styles and topics, the more accurate our transition matrix will be.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS 0 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Book processed:  huckleberry_finn.txt\n",
      "Book processed:  peter_pan.txt\n",
      "Book processed:  romeo_juliet.txt\n",
      "Book processed:  sherlock_holmes.txt\n",
      "Book processed:  sleepy_hollow.txt\n",
      "Book processed:  wizard_oz.txt\n",
      "before 36 [3.0000e+00 2.1620e+03 3.3160e+03 5.9360e+03 1.3100e+02 1.0140e+03\n",
      " 2.1700e+03 1.9700e+02 5.7880e+03 4.2000e+01 1.7900e+03 7.6350e+03\n",
      " 2.7610e+03 2.5720e+04 3.1000e+01 1.8850e+03 4.0000e+00 1.0815e+04\n",
      " 1.1927e+04 1.4263e+04 1.2120e+03 2.9950e+03 1.5390e+03 1.1900e+02\n",
      " 4.8020e+03 1.3000e+02 8.0630e+03 9.9000e+01 1.2700e+02 1.2000e+01\n",
      " 2.0000e+00 6.0000e+00 3.3000e+01 2.5700e+02 4.1000e+01 1.0000e+00]\n",
      "after 36 [2.56348908e-05 1.84742113e-02 2.83350993e-02 5.07229039e-02\n",
      " 1.11939023e-03 8.66459309e-03 1.85425710e-02 1.68335783e-03\n",
      " 4.94582493e-02 3.58888471e-04 1.52954848e-02 6.52407971e-02\n",
      " 2.35926445e-02 2.19776464e-01 2.64893872e-04 1.61072564e-02\n",
      " 3.41798544e-05 9.24137813e-02 1.01915781e-01 1.21876816e-01\n",
      " 1.03564959e-02 2.55921660e-02 1.31506990e-02 1.01685067e-03\n",
      " 4.10329152e-02 1.11084527e-03 6.88980415e-02 8.45951396e-04\n",
      " 1.08521038e-03 1.02539563e-04 1.70899272e-05 5.12697816e-05\n",
      " 2.81983799e-04 2.19605564e-03 3.50343508e-04 1.00000000e-05]\n"
     ]
    }
   ],
   "source": [
    "M = np.zeros((dim, dim))\n",
    "probs_all_chars = dim * [0.0]\n",
    "print(\"PROBS 0\", probs_all_chars)\n",
    "books_processed = [books for books in listdir(path_books)]\n",
    "for b in books_processed:\n",
    "    print(\"Book processed: \", b)\n",
    "    with open(path_books+b, 'r', encoding=\"latin-1\") as myfile:\n",
    "        current = myfile.read(1).lower()\n",
    "        while current not in chars_spc:\n",
    "            current = myfile.read(1).lower()\n",
    "        while True:\n",
    "            following = myfile.read(1).lower()\n",
    "            if not following: \n",
    "                break\n",
    "            if (following in chars_spc) & (current in chars_spc): \n",
    "                M[chars_ids[current],chars_ids[following]]+=1 \n",
    "            current = following\n",
    "print(\"before\", len(M),M[0])\n",
    "\n",
    "for i in range(dim):\n",
    "    M[i] = M[i]/sum(M[i])\n",
    "    for j in range(dim):\n",
    "        if M[i,j] < 0.00001:\n",
    "            M[i,j] = 0.00001\n",
    "            \n",
    "print(\"after\", len(M), M[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are on element-->  a\n",
      "0.21977646375226442\n",
      "MOST LIKELLY COMBINATION --> a n\n",
      "We are on element-->  b\n",
      "0.3170458462599104\n",
      "MOST LIKELLY COMBINATION --> b e\n",
      "We are on element-->  c\n",
      "0.19396486560033865\n",
      "MOST LIKELLY COMBINATION --> c o\n",
      "We are on element-->  d\n",
      "0.5385817542488768\n",
      "MOST LIKELLY COMBINATION --> d  \n",
      "We are on element-->  e\n",
      "0.31759019085586293\n",
      "MOST LIKELLY COMBINATION --> e  \n",
      "We are on element-->  f\n",
      "0.32674787950713813\n",
      "MOST LIKELLY COMBINATION --> f  \n",
      "We are on element-->  g\n",
      "0.2745181313296308\n",
      "MOST LIKELLY COMBINATION --> g  \n",
      "We are on element-->  h\n",
      "0.4650271546385204\n",
      "MOST LIKELLY COMBINATION --> h e\n",
      "We are on element-->  i\n",
      "0.2568061931953613\n",
      "MOST LIKELLY COMBINATION --> i n\n",
      "We are on element-->  j\n",
      "0.35396453663432587\n",
      "MOST LIKELLY COMBINATION --> j u\n",
      "We are on element-->  k\n",
      "0.31629414545208995\n",
      "MOST LIKELLY COMBINATION --> k e\n",
      "We are on element-->  l\n",
      "0.15846342627309293\n",
      "MOST LIKELLY COMBINATION --> l l\n",
      "We are on element-->  m\n",
      "0.2767366765103635\n",
      "MOST LIKELLY COMBINATION --> m e\n",
      "We are on element-->  n\n",
      "0.21457342004606192\n",
      "MOST LIKELLY COMBINATION --> n d\n",
      "We are on element-->  o\n",
      "0.16170340767478836\n",
      "MOST LIKELLY COMBINATION --> o u\n",
      "We are on element-->  p\n",
      "0.18343325692117793\n",
      "MOST LIKELLY COMBINATION --> p e\n",
      "We are on element-->  q\n",
      "0.9937943262411347\n",
      "MOST LIKELLY COMBINATION --> q u\n",
      "We are on element-->  r\n",
      "0.21923695586609027\n",
      "MOST LIKELLY COMBINATION --> r e\n",
      "We are on element-->  s\n",
      "0.31467772069126576\n",
      "MOST LIKELLY COMBINATION --> s  \n",
      "We are on element-->  t\n",
      "0.33115814139736305\n",
      "MOST LIKELLY COMBINATION --> t h\n",
      "We are on element-->  u\n",
      "0.18189647357447195\n",
      "MOST LIKELLY COMBINATION --> u t\n",
      "We are on element-->  v\n",
      "0.8066060704431098\n",
      "MOST LIKELLY COMBINATION --> v e\n",
      "We are on element-->  w\n",
      "0.23134050321651226\n",
      "MOST LIKELLY COMBINATION --> w a\n",
      "We are on element-->  x\n",
      "0.19061413673232908\n",
      "MOST LIKELLY COMBINATION --> x t\n",
      "We are on element-->  y\n",
      "0.4972859995008735\n",
      "MOST LIKELLY COMBINATION --> y  \n",
      "We are on element-->  z\n",
      "0.29934640522875816\n",
      "MOST LIKELLY COMBINATION --> z e\n",
      "We are on element-->   \n",
      "0.14440242671708794\n",
      "MOST LIKELLY COMBINATION -->   t\n",
      "We are on element-->  .\n",
      "0.8223014256619144\n",
      "MOST LIKELLY COMBINATION --> .  \n",
      "We are on element-->  ,\n",
      "0.9556648193674736\n",
      "MOST LIKELLY COMBINATION --> ,  \n",
      "We are on element-->  ;\n",
      "0.9992190550566185\n",
      "MOST LIKELLY COMBINATION --> ;  \n",
      "We are on element-->  :\n",
      "0.9732620320855615\n",
      "MOST LIKELLY COMBINATION --> :  \n",
      "We are on element-->  ?\n",
      "0.510932944606414\n",
      "MOST LIKELLY COMBINATION --> ? \"\n",
      "We are on element-->  !\n",
      "0.687992125984252\n",
      "MOST LIKELLY COMBINATION --> !  \n",
      "We are on element-->  -\n",
      "0.26068299660289646\n",
      "MOST LIKELLY COMBINATION --> - -\n",
      "We are on element-->  '\n",
      "0.30543093270365995\n",
      "MOST LIKELLY COMBINATION --> ' t\n",
      "We are on element-->  \"\n",
      "0.25613026819923373\n",
      "MOST LIKELLY COMBINATION --> \"  \n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in M:\n",
    "    print(\"We are on element--> \", chars_spc[counter])\n",
    "    print(max(i))\n",
    "    print(\"MOST LIKELLY COMBINATION -->\", chars_spc[counter],chars_spc[np.argmax(i)])\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have shown the most likelly combinations in our transition matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score of the dictionary\n",
    "For our algorithm we are going to maximize the log of the score for the pairs. We have deleted the 0s from the transition matrix and we are using log for not multiplying zeros that would lead to a zero total score. We need this to make comparisons between the differents approaches we are going to use as dictionary solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_score(string, transitionM):\n",
    "    sc = 0\n",
    "    for i in range(len(string)-1):\n",
    "        current = chars_ids[string[i]]\n",
    "        next_char = chars_ids[string[i+1]]\n",
    "        sc = sc + math.log(transitionM[current, next_char])\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial solution\n",
    "On the MC method we need an initial solution that we will try to improve. We will use a naive random solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_inverse = np.random.permutation(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo method\n",
    "As the method works we will do random samples combinations and we will check the performance for each combination. If that combination improves the perfomance of our deciphering dictionary we will keep it so that step by step we will converge to the best solution. As we know Monte Carlo methods rely on repeated random sampling to obtain numerical results.\n",
    "\n",
    "It may happen that after some permutation the next ones do not make any improvement at all so for optimizing the algorithm we will set an early stopping parameter **stop** for prematurely break the loop and we will be happy enough with the best combination already found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montecarlo(initial_inverse_permutation, ciphered_text, transition_matrix, ntries, stop):\n",
    "    dict_decipher = {}\n",
    "    for i in range(dim):\n",
    "        dict_decipher[chars_spc[i]] = chars_spc[initial_inverse_permutation[i]]\n",
    "    current_deciphered_list = []\n",
    "    for c in ciphered_text:\n",
    "        current_deciphered_list += [dict_decipher[c]]\n",
    "    current_deciphered_text=''.join(current_deciphered_list)\n",
    "    sc_current = log_score(current_deciphered_text, transition_matrix)\n",
    "    counter = 0\n",
    "    for i in range(ntries):\n",
    "        x, y = np.random.choice(dim, size=2, replace=False)\n",
    "        new = dict_decipher.copy()\n",
    "        new[chars_spc[x]] = dict_decipher[chars_spc[y]]\n",
    "        new[chars_spc[y]] = dict_decipher[chars_spc[x]]\n",
    "        new_deciphered_list = []\n",
    "        for c in ciphered_text:\n",
    "            new_deciphered_list += [new[c]]\n",
    "        new_deciphered_text=''.join(new_deciphered_list)\n",
    "        sc_new = log_score(new_deciphered_text, transition_matrix)\n",
    "        if(sc_new>sc_current): \n",
    "            dict_decipher = new\n",
    "            sc_current = sc_new\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter == stop: \n",
    "                print(\"Stopped after\", stop, \"iterations with no improvement.\")\n",
    "                break\n",
    "    return(dict_decipher, sc_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIPHERED TEXT:\n",
      "!ooq-dqu?-!do\"qn-dqzd! uq!gnbdad q-pbiq?nyqonbgqk dwpudoz?!apbgqopmmodqn qbnq-nbdzqpbq-zqkc ud,q!biqbnm?pbgqk! mpwco! qmnqpbmd dumq-dqnbqu?n d,qqm?ncg?mqqyncoiqu!poq!;ncmq!qopmmodq!biquddqm?dqy!md zqk! mqn'qm?dqyn oi\"qmqpuq!qy!zqq?!adqn'qi papbgqn''qm?dqukoddbq!biq dgco!mpbgqm?dqwp wco!mpnb\"q?dbdad qq'pbiq-zudo'qg nypbgqg p-q!;ncmqm?dq-ncm?lqy?dbdad qpmqpuq!qi!-k,qi p::ozqnad-;d qpbq-zquncolqy?dbdad qq'pbiq-zudo'qpbanocbm! pozqk!cupbgq;d'n dqwn''pbqy! d?ncudu,q!biq; pbgpbgqckqm?dq d! qn'qdad zq'cbd !oqq-ddmlq!biqdukdwp!oozqy?dbdad q-zq?zknuqgdmqucw?q!bqckkd q?!biqn'q-d,qm?!mqpmq dfcp duq!qum nbgq-n !oqk pbwpkodqmnqk dadbmq-dq' n-qidop;d !mdozqumdkkpbgqpbmnqm?dqum ddm,q!biq-dm?nipw!oozqhbnwhpbgqkdnkoduq?!muqn''m?db,qq!wwncbmqpmq?pg?qmp-dqmnqgdmqmnqud!q!uqunnbq!uqqw!b\"q?puqpuq-zquc;umpmcmdq'n qkpumnoq!biq;!oo\"qpm?q!qk?ponunk?pw!oq'onc pu?q!mnqm? nyuq?p-udo'qcknbq?puquyn ilqqfcpdmozqm!hdqmnqm?dqu?pk\"q?d dqpuqbnm?pbgquc k pupbgqpbqm?pu\"q'qm?dzq;cmqhbdyqpm,q!o-numq!ooq-dbqpbqm?dp qidg dd,qun-dqmp-dqn qnm?d ,qw?d pu?qad zqbd! ozqm?dqu!-dq'ddopbguqmny! iuqm?dqnwd!bqypm?q-d\n"
     ]
    }
   ],
   "source": [
    "ciphered_list = []\n",
    "with open(path_ciphered, 'r') as file:\n",
    "    for line in file: \n",
    "        ciphered_list += line[0]\n",
    "ciphered_text=''.join(ciphered_list)\n",
    "print(\"CIPHERED TEXT:\")\n",
    "print(ciphered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciphering\n",
    "Since MCMC are stocastic models we can run them more than one time and select the best solution. We need to initialize an initial best score and I will show the best and the worse model to see if there is much difference between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Dictionary number  1 Score:  -2584.3984249762066\n",
      "{'a': 'v', 'b': 'n', 'c': 'u', 'd': 'e', 'e': ':', 'f': 'q', 'g': 'g', 'h': 'k', 'i': 'd', 'j': '!', 'k': 'p', 'l': ';', 'm': 't', 'n': 'o', 'o': 'l', 'p': 'i', 'q': ' ', 'r': 'j', 's': '?', 't': '\"', 'u': 's', 'v': \"'\", 'w': 'c', 'x': '-', 'y': 'w', 'z': 'y', ' ': 'r', '.': 'x', ',': ',', ';': 'b', ':': 'z', '?': 'h', '!': 'a', '-': 'm', \"'\": 'f', '\"': '.'}\n",
      "Possible Dictionary number  2 Score:  -2584.3984249762066\n",
      "{'a': 'v', 'b': 'n', 'c': 'u', 'd': 'e', 'e': '?', 'f': 'q', 'g': 'g', 'h': 'k', 'i': 'd', 'j': '!', 'k': 'p', 'l': ';', 'm': 't', 'n': 'o', 'o': 'l', 'p': 'i', 'q': ' ', 'r': 'x', 's': \"'\", 't': ':', 'u': 's', 'v': 'j', 'w': 'c', 'x': '-', 'y': 'w', 'z': 'y', ' ': 'r', '.': '\"', ',': ',', ';': 'b', ':': 'z', '?': 'h', '!': 'a', '-': 'm', \"'\": 'f', '\"': '.'}\n",
      "Possible Dictionary number  3 Score:  -3702.9589413250837\n",
      "{'a': 'k', 'b': ' ', 'c': 'y', 'd': 's', 'e': 'x', 'f': 'z', 'g': 'h', 'h': '.', 'i': 'b', 'j': '?', 'k': 'd', 'l': 'v', 'm': 'e', 'n': 'l', 'o': '-', 'p': 'n', 'q': 'o', 'r': ',', 's': '\"', 't': ':', 'u': 't', 'v': 'q', 'w': 'a', 'x': ';', 'y': 'w', 'z': 'p', ' ': 'i', '.': '!', ',': 'c', ';': \"'\", ':': 'g', '?': 'r', '!': 'm', '-': 'u', \"'\": 'f', '\"': 'j'}\n",
      "Possible Dictionary number  4 Score:  -2973.042450807907\n",
      "{'a': 'v', 'b': 't', 'c': 'u', 'd': 'e', 'e': 'j', 'f': 'q', 'g': 'h', 'h': 'k', 'i': 'y', 'j': '\"', 'k': 'p', 'l': '!', 'm': 'n', 'n': 'o', 'o': 'l', 'p': 'i', 'q': ' ', 'r': '-', 's': '?', 't': 'x', 'u': 's', 'v': ':', 'w': 'c', 'x': 'z', 'y': 'w', 'z': '.', ' ': 'r', '.': \"'\", ',': ',', ';': 'b', ':': 'g', '?': 'd', '!': 'a', '-': 'm', \"'\": 'f', '\"': ';'}\n",
      "Stopped after 40000 iterations with no improvement.\n",
      "Possible Dictionary number  5 Score:  -2584.3984249762066\n",
      "{'a': 'v', 'b': 'n', 'c': 'u', 'd': 'e', 'e': ':', 'f': 'q', 'g': 'g', 'h': 'k', 'i': 'd', 'j': '!', 'k': 'p', 'l': ';', 'm': 't', 'n': 'o', 'o': 'l', 'p': 'i', 'q': ' ', 'r': 'j', 's': 'x', 't': '\"', 'u': 's', 'v': \"'\", 'w': 'c', 'x': '-', 'y': 'w', 'z': 'y', ' ': 'r', '.': '?', ',': ',', ';': 'b', ':': 'z', '?': 'h', '!': 'a', '-': 'm', \"'\": 'f', '\"': '.'}\n",
      "Stopped after 40000 iterations with no improvement.\n",
      "Possible Dictionary number  6 Score:  -3544.60215420541\n",
      "{'a': 'f', 'b': 'i', 'c': 'w', 'd': ' ', 'e': 'j', 'f': '\"', 'g': 'g', 'h': 'u', 'i': 'c', 'j': '!', 'k': '-', 'l': 'k', 'm': 'n', 'n': 's', 'o': 'o', 'p': 'a', 'q': 'e', 'r': 'q', 's': '?', 't': ',', 'u': 'r', 'v': ';', 'w': 'l', 'x': ':', 'y': \"'\", 'z': 'm', ' ': 'h', '.': 'x', ',': 'b', ';': '.', ':': 'z', '?': 'd', '!': 't', '-': 'y', \"'\": 'p', '\"': 'v'}\n",
      "DECIPHERED TEXT:\n",
      "all me shmael. ome years agonever mind how long preciselyhaving little or no money in my purse, and nothing particular to interest me on shore,  thought  would sail about a little and see the watery part of the world. t is a way  have of driving off the spleen and regulating the circulation. henever  find myself growing grim about the mouth; whenever it is a damp, drizzly ovember in my soul; whenever  find myself involuntarily pausing before coffin warehouses, and bringing up the rear of every funeral  meet; and especially whenever my hypos get such an upper hand of me, that it requires a strong moral principle to prevent me from deliberately stepping into the street, and methodically knocking peoples hats offthen,  account it high time to get to sea as soon as  can. his is my substitute for pistol and ball. ith a philosophical flourish ato throws himself upon his sword;  quietly take to the ship. here is nothing surprising in this. f they but knew it, almost all men in their degree, some time or other, cherish very nearly the same feelings towards the ocean with me\n",
      "SCORE OF THE TEXT: -2584.3984249762066\n",
      "worse DECIPHERED TEXT:\n",
      "m--ousotrums-jolusopsmitomhl sksioun borlwo-l hodisants-prmkn ho-nee-solio loul spon oupodyitscom bo lern hodmienay-mioelon esisteousol otrliscooerlyhreoowly-botmn-om'lyeomo-nee-som botssoersowmesipodmieolfoersowli-bjoeontomowmpoormksolfobinkn holffoersotd-ss om boishy-men hoersoaniay-menl jors sksioofn boupts-fohilwn hohinuom'lyeoersoulyervowrs sksioneontomobmudcobingg-polksu'sion oupotly-vowrs sksioofn boupts-fon kl-y emin-podmytn ho'sflisoalffn owmisrlytstcom bo'in hn hoydoersoismiolfosksipofy sim-ooussevom bostdsanm--powrs sksiouporpdltohseotyarom oyddsiorm bolfouscoermeoneoiszynistomoteil houlim-odin and-soelodisks eousofiluobs-n'simes-potesddn hon eloersoteissecom bouserlbnam--po. la.n hodsld-stormetolffers coomaaly eoneornhroenusoelohseoelotsmomtotll omtooam jorntontoupoty'teneyesofliodntel-om bo'm--joneromodrn-ltldrnam-of-lyintromeloerilwtornuts-foydl orntotwlibvoozynse-poem.soeloersotrndjorsisonto lern hotyidintn hon oerntjofoerspo'yeo. swonecom-ulteom--ous on oersniobshisscotlusoenusoliolersicoarsintroksipo smi-poersotmusofss-n htoelwmibtoersolasm ownerous\n",
      "SCORE OF THE TEXT: -3702.9589413250837\n"
     ]
    }
   ],
   "source": [
    "best_score = -999999\n",
    "worse_score = 0\n",
    "best_decipher = None\n",
    "list_tries = [10000,15000,20000,30000,60000,60000]\n",
    "for i in range(len(list_tries)):\n",
    "    decipher, score = montecarlo(naive_inverse, ciphered_text, M, list_tries[i], 40000)\n",
    "    print(\"Possible Dictionary number \",(i+1), \"Score: \",score)\n",
    "    print(decipher)\n",
    "    if score>best_score:\n",
    "        best_score=score\n",
    "        best_decipher=decipher\n",
    "    if score<worse_score:\n",
    "        worse_score = score\n",
    "        worst_decipher = decipher\n",
    "deciphered_list = []\n",
    "deciphered_w_list = []\n",
    "for c in ciphered_text:\n",
    "    deciphered_list += [best_decipher[c]]\n",
    "    deciphered_w_list += [worst_decipher[c]]\n",
    "    \n",
    "deciphered_text=''.join(deciphered_list)\n",
    "w_deciphered_text=''.join(deciphered_w_list)\n",
    "print(\"DECIPHERED TEXT:\")\n",
    "print(deciphered_text)\n",
    "print(\"SCORE OF THE TEXT:\", best_score)\n",
    "print(\"worse DECIPHERED TEXT:\")\n",
    "print(w_deciphered_text)\n",
    "print(\"SCORE OF THE TEXT:\", worse_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final conclusion\n",
    "\n",
    "As we can see, the best model performs much better than the worse as MCMC is an stochastical model and we might obtain different solutions each time we run the model. Although the more iterations we include on our model the better it should performs, this is not always true just because of the random characteristic of the method,  when it does not reach the stopping condition.  I have also shown how the worse decipher works and we can see there are clear differences between the worse and best model and big differences on the text deciphered. As a curiosity, I have searched the text on google and it seems to be from the first chapter of Moby Dick, which is an indicator of the correct working of my algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
